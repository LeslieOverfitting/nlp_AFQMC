{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bert.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1K9MFD8CJscBhWMwiUtkH7lRz6DOFwjWM","authorship_tag":"ABX9TyMQD3br4+8NkfLwXRhKsACn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{},"colab_type":"code","executionInfo":{"elapsed":1341,"status":"ok","timestamp":1592895406974,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"},"user_tz":-480},"id":"H0s5HROJG2fq"},"outputs":[],"source":["import os\n","path = \"/content/drive/My Drive/NLP/nlp_AFQMC\"\n","os.chdir(path)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":583},"colab_type":"code","executionInfo":{"elapsed":10907,"status":"ok","timestamp":1592895873141,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"},"user_tz":-480},"id":"iN_Oi-01IPtx","outputId":"ee2ab24c-dcd3-4938-8924-ba64471875d0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n","\u001b[K     |████████████████████████████████| 675kB 2.7MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 6.8MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Collecting tokenizers==0.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 12.9MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 32.9MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.2)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=70f9acf98fc7abd4d0f28a2c8851002fae42c1ee05326aad9e53d2b5eb891355\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.11.0\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{},"colab_type":"code","executionInfo":{"elapsed":20579,"status":"ok","timestamp":1592895882946,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"},"user_tz":-480},"id":"OO-kiRPAG3fg"},"outputs":[],"source":["import time\n","import json\n","import random\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import pandas as pd\n","import transformers\n","from sklearn import metrics\n","from transformers import AdamW\n","from transformers import get_linear_schedule_with_warmup\n","from transformers import BertTokenizer,BertConfig\n","from transformers import BertModel,BertForSequenceClassification\n","from torch.optim import lr_scheduler\n","from utils import get_time_diff, print_ans, EarlyStopping\n","from torch.utils.data import DataLoader, Dataset\n","from config import Config\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{},"colab_type":"code","executionInfo":{"elapsed":20474,"status":"ok","timestamp":1592895882947,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"},"user_tz":-480},"id":"nN-E3WMQcg2E"},"outputs":[],"source":["%reload_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{},"colab_type":"code","executionInfo":{"elapsed":20369,"status":"ok","timestamp":1592895882948,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"},"user_tz":-480},"id":"v8naAzU0pD_W"},"outputs":[],"source":["def seed_everything(seed):\n","    # 设置随机种子\n","    random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","seed_everything(42)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{},"colab_type":"code","executionInfo":{"elapsed":20203,"status":"ok","timestamp":1592895882949,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"},"user_tz":-480},"id":"uqh4uVldINL9"},"outputs":[],"source":["class SentenceDataset(Dataset):\n","    def __init__(self, df, config):\n","        self.df = df\n","        self.max_len = config.max_len\n","        self.labeled = 'label' in df\n","        self.tokenizer = BertTokenizer.from_pretrained(config.bert_vocab_path)\n","        #self.tokenizer = BertTokenizer.from_pretrained(\"bert-base-chinese\") \n","\n","    def __getitem__(self, index):\n","        data = {}\n","        row = self.df.iloc[index]\n","        input_features = self.tokenizer.encode_plus(str(row.sentence1), str(row.sentence2), \n","                            max_length=self.max_len * 2, pad_to_max_length=True, add_special_tokens=True,\n","                            return_token_type_ids=True, return_attention_mask=True)\n","        data['ids'] = torch.tensor(input_features['input_ids']) # 获取token id\n","        data['masks'] = torch.tensor(input_features['attention_mask']) # 获取掩码\n","        data['token_type_ids'] = torch.tensor(input_features['token_type_ids']) # 获取句子归属\n","        \n","        if self.labeled:\n","            data['label'] = torch.tensor(row.label)\n","        return data\n","      \n","    def __len__(self):\n","        return len(self.df)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{},"colab_type":"code","executionInfo":{"elapsed":20036,"status":"ok","timestamp":1592895882949,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"},"user_tz":-480},"id":"Ff0roTO1Rz-J"},"outputs":[],"source":["def get_dataLoader(sentence_dataset, batch_size, shuffle=True): \n","    # 获取 data loader\n","    loader = DataLoader(\n","        sentence_dataset,\n","        batch_size=batch_size,\n","        shuffle=shuffle,\n","        drop_last=False\n","    )\n","    return loader\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{},"colab_type":"code","executionInfo":{"elapsed":19838,"status":"ok","timestamp":1592895882950,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"},"user_tz":-480},"id":"nT-sr5X83SLW"},"outputs":[],"source":["class FGM():\n","    # 对抗训练\n","    def __init__(self, model):\n","        self.model = model\n","        self.backup = {}\n","\n","    def attack(self, epsilon=1., emb_name='word_embeddings'):\n","        # 对词嵌入进行扰动\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and emb_name in name:\n","                self.backup[name] = param.data.clone()\n","                norm = torch.norm(param.grad)\n","                if norm != 0:\n","                    r_at = epsilon * param.grad / norm\n","                    param.data.add_(r_at)\n","\n","    def restore(self, emb_name='word_embeddings'):\n","         # 恢复\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and emb_name in name:\n","                assert name in self.backup\n","                param.data = self.backup[name]\n","        self.backup = {}"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{},"colab_type":"code","executionInfo":{"elapsed":19574,"status":"ok","timestamp":1592895882950,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"},"user_tz":-480},"id":"Tu1i87QxSeza"},"outputs":[],"source":["class BertModelBase(nn.Module):\n","    # bert 模型\n","    def __init__(self, config, mulit_dropout=False):\n","        super(BertModelBase, self).__init__()\n","        self.bert_config = BertConfig.from_pretrained(\n","            config.bert_config_path, output_hidden_states=True)      \n","        self.bert = BertModel.from_pretrained(\n","            config.bert_model_path, config=self.bert_config)\n","        self.fc = nn.Linear(self.bert_config.hidden_size, 2)\n","        self.mulit_dropout = mulit_dropout\n","        self.dropout = nn.Dropout(0.2)\n","        self.dropouts = nn.ModuleList([nn.Dropout(0.2) for _ in range(6)])\n","        nn.init.normal_(self.fc.weight, mean=0.0, std=0.02)\n","        nn.init.normal_(self.fc.bias, 0)\n","\n","    def forward(self, input_ids, token_type_ids, attention_mask):\n","        last_hidden_state, pooler_output, hidden_states = self.bert(input_ids=input_ids, \n","                                        attention_mask=attention_mask,\n","                                        token_type_ids=token_type_ids)\n","        if self.mulit_dropout: # multi sample dropout\n","            predict = torch.mean(\n","                torch.stack(\n","                    [self.fc(dropout(pooler_output)) for dropout in self.dropouts],\n","                    dim=0\n","                ),\n","                dim=0\n","            )\n","        else:\n","            predict = self.fc(self.dropout(pooler_output))\n","        return predict"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{},"colab_type":"code","executionInfo":{"elapsed":19126,"status":"ok","timestamp":1592895882951,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"},"user_tz":-480},"id":"XynK4kSfC_hN"},"outputs":[],"source":["def get_loss(pred, label, smoothing=True, eps=0.1):\n","  # 标签平滑，未加入进行实验\n","  if smoothing:\n","    log_pred = F.log_softmax(pred, dim=1)\n","    one_hot = torch.zeros_like(pred).scatter(1, label.view(-1,1), 1)\n","    smooth_label = one_hot * (1.0 - eps) + (1.0 - one_hot) * eps\n","    loss = -(log_pred * smooth_label)\n","    loss = loss.sum(dim=-1).mean()\n","    return loss\n","  else:\n","    return F.cross_entropy(pred, label)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{},"colab_type":"code","executionInfo":{"elapsed":18672,"status":"ok","timestamp":1592895882952,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"},"user_tz":-480},"id":"At8DXKvmTwUi"},"outputs":[],"source":["def train(data_loader, model, device, optimizer, use_fgm=True):\n","    # 训练模型\n","    optimizer.zero_grad()\n","    model.train()\n","    start_time = time.time()\n","    criterion = nn.CrossEntropyLoss()\n","    if use_fgm: # 开启对抗训练\n","        fgm = FGM(model)\n","    for i, batch in enumerate(data_loader):\n","        ids = batch['ids']\n","        masks = batch['masks']\n","        token_type_ids = batch['token_type_ids']\n","        labels = batch['label']\n","        ids = ids.to(device, dtype=torch.long)\n","        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n","        masks = masks.to(device, dtype=torch.long)\n","        labels = labels.to(device, dtype=torch.long)\n","        optimizer.zero_grad()\n","        outputs = model(ids, token_type_ids, masks)\n","        loss = criterion(outputs.view(-1, 2), labels.view(-1))\n","        loss.backward()\n","        # trick 对抗训练\n","        if use_fgm:\n","            fgm.attack()  ##对抗训练\n","            adv_outputs = model(ids, token_type_ids, masks)\n","            loss_adv = criterion(adv_outputs.view(-1, 2), labels.view(-1))\n","            loss_adv.backward()\n","            fgm.restore()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # 梯度截断\n","        optimizer.step()\n","        if (i + 1) % 200 == 0:\n","            true_label = labels.data.cpu().numpy()\n","            predict = torch.max(outputs, dim=1)[1].cpu().numpy()\n","            train_acc = metrics.accuracy_score(true_label, predict)\n","            time_diff = get_time_diff(start_time)\n","            msg = 'Iter:{0:>6} Train loss: {1:>5.3} Train acc:{2:>6.2%} Time:{3}'\n","            print(msg.format(i + 1, loss.item(), train_acc, time_diff))\n","\n","def dev(data_loader, model, device):\n","    # 验证集验证\n","    model.eval()\n","    total_loss = 0\n","    predicts_all = np.array([], dtype=int)\n","    labels_all = np.array([], dtype=int)\n","    criterion = nn.CrossEntropyLoss()\n","    start_time = time.time()\n","    with torch.no_grad():\n","        for batch in data_loader:\n","            ids = batch['ids']\n","            masks = batch['masks']\n","            token_type_ids = batch['token_type_ids']\n","            labels = batch['label']\n","            ids = ids.to(device, dtype=torch.long)\n","            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n","            masks = masks.to(device, dtype=torch.long)\n","            labels = labels.to(device, dtype=torch.long)\n","            outputs = model(ids, token_type_ids, masks)\n","            loss = criterion(outputs, labels.view(-1))\n","            total_loss += loss.item()\n","            predict = torch.max(outputs, dim=1)[1].cpu().numpy()\n","            labels = labels.data.cpu().numpy()\n","            labels_all = np.append(labels_all, labels)\n","            predicts_all = np.append(predicts_all, predict)\n","    acc = metrics.accuracy_score(labels_all, predicts_all)\n","    report = metrics.classification_report(labels_all, predicts_all, digits=4)\n","    confusion = metrics.confusion_matrix(labels_all, predicts_all)\n","    f1_score = metrics.f1_score(labels_all, predicts_all, average='macro')\n","    return acc, total_loss / len(data_loader), report, confusion, f1_score\n","\n","def inference(config):\n","    # 预测\n","    predicts_all = np.array([], dtype=int)\n","    test_df = pd.read_csv(config.test_data_path)\n","    test_dataset = SentenceDataset(test_df, config)\n","    test_loader = get_dataLoader(test_dataset, config.batch_size, shuffle=False)\n","    device = config.device\n","    model = BertModelBase(config)\n","    model.to(device)\n","    model.eval()\n","    with torch.no_grad():\n","      for batch in test_loader:\n","        ids = batch['ids']\n","        masks = batch['masks']\n","        token_type_ids = batch['token_type_ids']\n","        ids = ids.to(device, dtype=torch.long)\n","        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n","        masks = masks.to(device, dtype=torch.long)\n","        outputs = model(ids, token_type_ids, masks)\n","        predict = torch.max(outputs, dim=1)[1].cpu().numpy()\n","        predicts_all = np.append(predicts_all, predict)\n","\n","    output_submit_file = os.path.join(config.predict_output_path)\n","    # 保存标签结果\n","    with open(output_submit_file, \"w\") as writer:\n","        for i, pred in enumerate(predicts_all):\n","            json_d = {}\n","            json_d['id'] = i\n","            json_d['label'] = str(pred)\n","            writer.write(json.dumps(json_d) + '\\n')"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{},"colab_type":"code","executionInfo":{"elapsed":18095,"status":"ok","timestamp":1592895882952,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"},"user_tz":-480},"id":"-aCoOJ5VXTBJ"},"outputs":[],"source":["def run(config):\n","    # 加载数据\n","    train_df = pd.read_csv(config.train_data_path)\n","    dev_df = pd.read_csv(config.dev_data_path)\n","    train_dataset = SentenceDataset(train_df, config)\n","    dev_dataset = SentenceDataset(dev_df, config)\n","    train_loader = get_dataLoader(train_dataset, config.batch_size, shuffle=False)\n","    dev_loader = get_dataLoader(dev_dataset, config.batch_size, shuffle=False)\n","    # 加载模型\n","    model = BertModelBase(config, True)\n","    model.to(config.device)\n","    no_decay = [\"bias\", \"LayerNorm.weight\"]\n","    param_optimizer = list(model.named_parameters())\n","    optimizer_parameters = [\n","        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n","        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n","    ]\n","    optimizer = AdamW(optimizer_parameters, lr=config.learn_rate, betas=(0.9, 0.999))\n","    es = EarlyStopping(patience=2)\n","    dev_best_loss = float('inf')\n","    # 开始训练\n","    for i in range(config.epoch_num):\n","        train(train_loader, model, config.device, optimizer)\n","        dev_acc, dev_loss, report, confusion, f1_score = dev(dev_loader, model, config.device)\n","        print_ans(dev_acc, dev_loss, report, confusion)\n","        es(f1_score, model, config.model_save_path)\n","        if es.early_stop:\n","          print(\"Early stopping\")\n","          break\n","    # 载入最优模型\n","    model.load_state_dict(torch.load(config.model_save_path))\n","    dev_acc, dev_loss, report, confusion, f1_score = dev(dev_loader, model, config.device)\n","    print_ans(dev_acc, dev_loss, report, confusion)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{},"colab_type":"code","executionInfo":{"elapsed":17925,"status":"ok","timestamp":1592895883373,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"},"user_tz":-480},"id":"6YTTyN6TaDfP"},"outputs":[],"source":["config = Config()\n","config.model_save_path = 'saveModel/bert_base.pt'\n","config.learn_rate = 2e-5 # 调低学习率，不然效果特别差"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"colab_type":"code","executionInfo":{"elapsed":1897312,"status":"ok","timestamp":1592897763296,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"},"user_tz":-480},"id":"XwRoCJAYaU-g","outputId":"2f82a935-84f9-44d0-c93d-60400edb3670"},"outputs":[{"name":"stderr","output_type":"stream","text":["Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated\n","Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated\n"]},{"name":"stdout","output_type":"stream","text":["Iter:   200 Train loss: 0.613 Train acc:67.19% Time:0:02:47\n","Iter:   400 Train loss: 0.492 Train acc:75.00% Time:0:05:33\n","Dev Loss: 0.51, Dev Acc:71.99%\n","Precision, Recall and F1-Score...\n","              precision    recall  f1-score   support\n","\n","           0     0.7445    0.9043    0.8167      2978\n","           1     0.5923    0.3094    0.4065      1338\n","\n","    accuracy                         0.7199      4316\n","   macro avg     0.6684    0.6069    0.6116      4316\n","weighted avg     0.6973    0.7199    0.6895      4316\n","\n","Confusion Matrix...\n","[[2693  285]\n"," [ 924  414]]\n","Validation score improved (-inf --> 0.6115797101611097). Saving model!\n","Iter:   200 Train loss: 0.523 Train acc:71.88% Time:0:02:46\n","Iter:   400 Train loss: 0.421 Train acc:84.38% Time:0:05:32\n","Dev Loss:  0.5, Dev Acc:73.84%\n","Precision, Recall and F1-Score...\n","              precision    recall  f1-score   support\n","\n","           0     0.7951    0.8365    0.8153      2978\n","           1     0.5883    0.5202    0.5522      1338\n","\n","    accuracy                         0.7384      4316\n","   macro avg     0.6917    0.6783    0.6837      4316\n","weighted avg     0.7310    0.7384    0.7337      4316\n","\n","Confusion Matrix...\n","[[2491  487]\n"," [ 642  696]]\n","Validation score improved (0.6115797101611097 --> 0.6837065134623378). Saving model!\n","Iter:   200 Train loss: 0.377 Train acc:82.81% Time:0:02:46\n","Iter:   400 Train loss: 0.274 Train acc:92.19% Time:0:05:32\n","Dev Loss: 0.54, Dev Acc:73.66%\n","Precision, Recall and F1-Score...\n","              precision    recall  f1-score   support\n","\n","           0     0.7851    0.8512    0.8168      2978\n","           1     0.5925    0.4813    0.5311      1338\n","\n","    accuracy                         0.7366      4316\n","   macro avg     0.6888    0.6663    0.6740      4316\n","weighted avg     0.7254    0.7366    0.7283      4316\n","\n","Confusion Matrix...\n","[[2535  443]\n"," [ 694  644]]\n","EarlyStopping counter: 1 out of 2\n","Iter:   200 Train loss:  0.41 Train acc:82.81% Time:0:02:46\n","Iter:   400 Train loss:  0.14 Train acc:96.88% Time:0:05:32\n","Dev Loss: 0.64, Dev Acc:73.26%\n","Precision, Recall and F1-Score...\n","              precision    recall  f1-score   support\n","\n","           0     0.7762    0.8606    0.8162      2978\n","           1     0.5907    0.4477    0.5094      1338\n","\n","    accuracy                         0.7326      4316\n","   macro avg     0.6835    0.6542    0.6628      4316\n","weighted avg     0.7187    0.7326    0.7211      4316\n","\n","Confusion Matrix...\n","[[2563  415]\n"," [ 739  599]]\n","EarlyStopping counter: 2 out of 2\n","Early stopping\n","Dev Loss:  0.5, Dev Acc:73.84%\n","Precision, Recall and F1-Score...\n","              precision    recall  f1-score   support\n","\n","           0     0.7951    0.8365    0.8153      2978\n","           1     0.5883    0.5202    0.5522      1338\n","\n","    accuracy                         0.7384      4316\n","   macro avg     0.6917    0.6783    0.6837      4316\n","weighted avg     0.7310    0.7384    0.7337      4316\n","\n","Confusion Matrix...\n","[[2491  487]\n"," [ 642  696]]\n"]}],"source":["run(config)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"colab_type":"code","executionInfo":{"elapsed":36591,"status":"ok","timestamp":1592871807234,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"},"user_tz":-480},"id":"bV5WelPKarBq","outputId":"6701e651-8e64-41bc-d4a6-b3a44651c1b0"},"outputs":[{"name":"stderr","output_type":"stream","text":["Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated\n"]}],"source":["inference(config)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"colab_type":"code","executionInfo":{"elapsed":1943,"status":"ok","timestamp":1592843324237,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"},"user_tz":-480},"id":"TqibA_aYctsE","outputId":"596d8cbe-ed0e-463e-b2ab-3641bc3eab16"},"outputs":[{"data":{"text/plain":["14899"]},"execution_count":57,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["import gc\n","gc.collect() "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"jGGJeE1kh53H"},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"jg6BGgG102_T"},"outputs":[],"source":[""]}]}